<center><img src='capa.png'></center>

<h1 align="center"> 
	📌 About me 
</h1>
 
Well, I'm 22 years old, living in Ipanema, Minas Gerais, Brazil.

I'm graduating in Control and Automation Engineering and I've always been passionate about technology but the career opportunities always took me to another path, until I finally decided to drop everything and go after my dream. I am currently working as a Data Scientist at precato, a fintech company focused on the purchase of precatórios, where I work directly with python projects and test automation and model implementation.

Currently I invest my time in learning about data engineering, an area I fell in love with.
--

<h1 align="center"> 
	🎓 Education
</h1>

* Machine Learning and Data Science with Python of A to Z:  [Certificate](https://udemy-certificate.s3.amazonaws.com/image/UC-0cbba4ac-04ba-4667-9a8e-5b184d68360f.jpg?v=1627663154000)
	> With this course I was able to learn about a good part of a data scientist's pipeline considering from data preparation to application of supervised to unsupervised algorithms. In the course it was also proposed several use cases.

* TensorFlow: Machine Learning and Deep Learning with Python:  [Certificate](https://udemy-certificate.s3.amazonaws.com/image/UC-b622d7ad-d7e4-4af4-a407-f9bc463428bb.jpg?v=1627664225000)
	> Theory and practice of how to build artificial neural networks to solve real problems of the day with convolutional neural networks, recurrent neural networks, autoencoders, and robust generative adversarial networks using TensorFlow were proposed in the course.

* SQL and NoSQL Databases from basic to advanced:  [Certificate](https://www.geekuniversity.com.br/media/solicitacao/certificados/54ebff03-6e76-46f2-b6d5-213c17f76f3f.png) 
	> With course I learned to use different SQL and NoSQL Database Management Systems, model relational databases applying the five normal ways.
**[MySQL, PostgreSQL, SQLite, MongoDB,Redis, CouchDB,and Firehouse]**

* HOWBootcamps Engenharia de dados: [Certificate](https://github.com/Tiao553/tiao553/blob/1494f3af333e42005cf3b5bf5052e4ad064ef454/Sebasti%C3%A3o%20-%20Data%20Engineering%20-%20May%202021.pdf)
	> In this bootcamp it was proposed to build a pipeline with lambda architecture. Where we use the infrastructure as AWS CDK code, create a datalake and a datawarehouse, process data with databricks, orchestrate tasks with airflow and automate tests and processes.

<h1 align="center"> 
	🛠️ Programing languages
</h1>

 <div align="center">
	<a href="https://github.com/Tiao553">
	<img height="180em" src="https://github-readme-stats.vercel.app/api/top-langs/?username=Tiao553&layout=compact&langs_count=7&theme=draula"/>
	<img height="180em" src="https://github-readme-stats.vercel.app/api?username=Tiao553&show_icons=true&theme=draula&include_all_commits=true&count_private=true"/>
 </div>

---
	
<center><img src='portifolio.png'></center>

<h2 align="center"> 
	Projects about the Data Science
</h2>

* ### Analyzing the Violence in Rio de Janeiro [PT-BR]: [link](https://github.com/Tiao553/Data_Science_repo/blob/master/Analise_rio/Analisando_a_Viol%C3%AAncia_no_Rio_de_Janeiro.ipynb)
	>  A descriptive analysis was made with the objective of understanding which were the main influencers of the high violence observed in Rio de Janeiro.

* ### Airbnb Data Analysis, Buenos Aires, Argentina [PT-BR]: [link](https://bit.ly/3idzxhE)
	>  Descriptive analysis on the data provided by Airbnb in order to understand which neighborhoods are the best to rent according to price and location.

* ### Features engineering, learn interactively [EN-US]: [link](https://www.linkedin.com/pulse/would-you-like-see-interactive-form-feature-ferreira-de-paula-neto/?trackingId=aGkbqpVpQ%2BqLf4YjyiANsA%3D%3D)
	>  One way to improve the performance of a model is feature enginerring. In this article I show how to apply this technique in a simple interactive way.


<h2 align="center"> 
	Projects about the Data engineer
</h2>

* ### **[AWS]** Building a lambda pipeline with CDK [PT-BR] : [Link](https://github.com/Tiao553/pipeline_lambda_as_CDK)
	>  This pipeline architecture is widely used in cases where the data is integrated all in one zone. In addition, it has 3 storage stages (bronze, silver, gold). Curious? Go to the repositor at link above.

* ### **[GCP]** Hackathon A3data [PT-BR] : [link](https://github.com/Tiao553/hackathon-A3Data-Ipating)
	>  A very cool challenge that contemplated the treatment and analysis of a large set of data. In this repository you can see my project carried out in this competition.

* ### Data Collection Pipeline in Yahoo Finance [PT-BR] : [link](https://github.com/Tiao553/project-data-forex)
	>  Back to the origins. I entered the market with many cloud-oriented solutions. With that in mind I worked on this project creating instances of **Hadoop, spark, and Hive** to get an experience with these tools.

---
<hr>

## ✅ Get in contact with me! ✉️

[![author](https://img.shields.io/badge/Linkedin-Sebastiao-blue.svg)](https://www.linkedin.com/in/sebasti%C3%A3o-ferreira-de-paula-neto-84673216b/) 
[![](https://img.shields.io/badge/medium-Sebastiao553-yellow.svg)](https://sebastiao--553.medium.com/)
